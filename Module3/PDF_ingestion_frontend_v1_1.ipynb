{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Powered Graph Queries"
      ],
      "metadata": {
        "id": "7Y10pmtWPGCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Set-up"
      ],
      "metadata": {
        "id": "EKyxrf1hPOlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip uninstall openai langchain-openai langchain_community langchain"
      ],
      "metadata": {
        "id": "SynoVY8dkm78"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "H44GKnYwMIOC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install openai langchain-openai langchain_community langchain\n",
        "%pip install graphdatascience"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get your Sandbox credentials and enter them here below\n",
        "\n",
        "connectionUrl = 'bolt://54.211.73.159:7687'\n",
        "username = 'neo4j'\n",
        "password = 'timers-basin-topic'"
      ],
      "metadata": {
        "id": "FtWDT_MmM-YP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "HXHdVROhsUYZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check our OpenAI connection"
      ],
      "metadata": {
        "id": "dRAJmpu_PRlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('open_key')\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "z1FmlG3sZuzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(openai_api_key=openai.api_key )\n",
        "\n",
        "response = llm.invoke(\"What is Neo4j?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "oGtTWoEiM-NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to Query"
      ],
      "metadata": {
        "id": "0OzCQ8f8PVzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a simple example query - testing the connection"
      ],
      "metadata": {
        "id": "FutRVdfd0W26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=connectionUrl,\n",
        "    username=\"neo4j\",\n",
        "    password=password\n",
        ")\n",
        "\n",
        "result = graph.query(\"\"\"\n",
        "MATCH (n:Paper) return n.name\n",
        "\"\"\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "PohyzC9frTVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph.schema)"
      ],
      "metadata": {
        "id": "DrolIHous75T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter your question\n",
        "\n",
        "*Keep it within the confines on the graph schema*"
      ],
      "metadata": {
        "id": "Y2rgcwA20gyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_phrase = input(\"Search phrase:\")"
      ],
      "metadata": {
        "id": "DiGpczR00yoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=\"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\"\n",
        ")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "     url=connectionUrl,\n",
        "    username=\"neo4j\",\n",
        "    password=password\n",
        ")\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "cypher_generation_prompt = PromptTemplate(\n",
        "    template=CYPHER_GENERATION_TEMPLATE,\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        ")\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "cypher_chain.invoke({\"query\": search_phrase})"
      ],
      "metadata": {
        "id": "LYx7t1chuJmX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}