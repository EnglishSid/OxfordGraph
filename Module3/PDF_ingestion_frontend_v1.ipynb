{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y10pmtWPGCf"
      },
      "source": [
        "# LLM Powered Graph Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKyxrf1hPOlo"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H44GKnYwMIOC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install langchain\n",
        "%pip install langchain_openai\n",
        "%pip install openai\n",
        "%pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FtWDT_MmM-YP"
      },
      "outputs": [],
      "source": [
        "#Get your Sandbox credentials and enter them here below\n",
        "\n",
        "connectionUrl = 'bolt://18.234.79.182:7687'\n",
        "username = 'neo4j'\n",
        "password = 'seconds-future-knife'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRAJmpu_PRlh"
      },
      "source": [
        "### Check our OpenAI connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGtTWoEiM-NS"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=\"sk-0j.....\")\n",
        "\n",
        "response = llm(\"What is a neo4j?\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OzCQ8f8PVzX"
      },
      "source": [
        "## Text to Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpAumgUUNffM"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=\"sk-0j.....\")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=connectionUrl,\n",
        "    username=username,\n",
        "    password=password,\n",
        ")\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "cypher_generation_prompt = PromptTemplate(\n",
        "    template=CYPHER_GENERATION_TEMPLATE,\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        ")\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "cypher_chain.invoke({\"query\": \"What are the technologies detailed within the papers?\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
